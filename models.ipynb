{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "u7KD22fJ4xNL",
        "cT06J4_NzTEf",
        "VJ2EggmV61iH"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dashcam Models (Colab version)"
      ],
      "metadata": {
        "id": "h6langIxOeZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use GPU runtime (L4 or T4 recommended)"
      ],
      "metadata": {
        "id": "6wacpym-O0xU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "mROvNN-VOs05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure latest version of tensorflow\n",
        "# Note: Colab is sometimes a few versions behind documentation\n",
        "!pip install tensorflow --upgrade\n",
        "!pip install tf-keras --upgrade\n",
        "!pip install tf-keras-vis"
      ],
      "metadata": {
        "id": "TVTI7sE4OzMS",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard data imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Files\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Image\n",
        "from PIL import Image\n",
        "\n",
        "# ML modeling imports\n",
        "import tensorflow as tf\n",
        "from tf_keras_vis.saliency import Saliency\n",
        "from tf_keras_vis.utils.scores import BinaryScore"
      ],
      "metadata": {
        "id": "Ezt6UaMxOsaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "t_hFyP74Pwzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"drive/MyDrive/dashcam-ai\" # Path to data zip file (change as needed)\n",
        "DATA_FOLDER_NAME = \"slowroads dataset\" # Name of folder generated from zip extraction\n",
        "TEST_FOLDER_NAME = \"test set\" # Same as above for test set"
      ],
      "metadata": {
        "id": "eTDWEgQSaEJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Unzip data\n",
        "with zipfile.ZipFile(f\"{DATA_PATH}/{DATA_FOLDER_NAME}.zip\", 'r') as f:\n",
        "    f.extractall(\"/content\")\n",
        "\n",
        "train = tf.data.Dataset.load(f\"/content/{DATA_FOLDER_NAME}/train\")\n",
        "val = tf.data.Dataset.load(f\"/content/{DATA_FOLDER_NAME}/val\")\n",
        "\n",
        "# Unzip test datasets\n",
        "with zipfile.ZipFile(f\"{DATA_PATH}/{TEST_FOLDER_NAME}.zip\", 'r') as f:\n",
        "    f.extractall(\"/content\")\n",
        "\n",
        "\n",
        "easy = tf.data.Dataset.load(f\"/content/{TEST_FOLDER_NAME}/easy\")\n",
        "hard = tf.data.Dataset.load(f\"/content/{TEST_FOLDER_NAME}/hard\")\n",
        "guard = tf.data.Dataset.load(f\"/content/{TEST_FOLDER_NAME}/metal guard\")\n",
        "fence = tf.data.Dataset.load(f\"/content/{TEST_FOLDER_NAME}/wood fence\")"
      ],
      "metadata": {
        "id": "NMYEgAvuaGMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually inspect dataset\n",
        "ds = val\n",
        "sample_index = 22\n",
        "\n",
        "# Show selected sample\n",
        "curr_index = 0\n",
        "for x, y in ds:\n",
        "    # Skip unselected samples\n",
        "    if curr_index != sample_index:\n",
        "        curr_index += 1\n",
        "\n",
        "        continue\n",
        "\n",
        "    # Show and stop iterating\n",
        "    plt.imshow(x)\n",
        "    break"
      ],
      "metadata": {
        "id": "9dZUVCphcwqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "tWSdXED4hWty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilities\n",
        "- Random seeds\n",
        "- Toy training data (single-sample \"dataset\" for fast debug)\n",
        "- Saliency map\n",
        "- Parameter counter\n",
        "- Basic trainer"
      ],
      "metadata": {
        "id": "u7KD22fJ4xNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEEDS = [3141, 2718, 1414, 2024]"
      ],
      "metadata": {
        "id": "fNK24vDhi_yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toy_train = None\n",
        "\n",
        "for x, y in train:\n",
        "    toy_train = tf.data.Dataset.from_tensor_slices(([x], [y]))\n",
        "    break"
      ],
      "metadata": {
        "id": "6nJoqfNBtBeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_saliency(model, x):\n",
        "    # Create saliency object\n",
        "    saliency = Saliency(model, clone=False)\n",
        "    score = BinaryScore([0])\n",
        "\n",
        "    # Compute and noramlize map\n",
        "    map = saliency(score, x, smooth_samples=20, smooth_noise=0.2)\n",
        "    map = (map - map.min())/(map.max() - map.min())\n",
        "\n",
        "    return map"
      ],
      "metadata": {
        "id": "FiCTWA5745VU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_params(model):\n",
        "    params = 0\n",
        "\n",
        "    for layer in model.layers:\n",
        "        for variable in layer.trainable_variables:\n",
        "            shape = variable.shape\n",
        "            params += np.prod(shape)\n",
        "\n",
        "    return params"
      ],
      "metadata": {
        "id": "746j6x8F5JgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_acc(model, batched_ds):\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        "    )\n",
        "\n",
        "    loss, acc = model.evaluate(\n",
        "        x=batched_ds,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    return acc"
      ],
      "metadata": {
        "id": "_STTvE3Hqrfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GetBestWeights(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, metric=\"val_loss\", max_=False):\n",
        "        self.metric = metric\n",
        "        self.max = max_\n",
        "\n",
        "        self.best = float(\"-inf\") if max_ else float(\"inf\")\n",
        "        self.best_weights = None\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Get metric\n",
        "        metric = logs[self.metric]\n",
        "\n",
        "        # Do not update if not improved\n",
        "        if (self.max) and (metric < self.best):\n",
        "            return\n",
        "\n",
        "        if (not self.max) and (metric > self.best):\n",
        "            return\n",
        "\n",
        "        # Update if improved\n",
        "        self.best = metric\n",
        "        self.best_weights = self.model.get_weights()"
      ],
      "metadata": {
        "id": "YYcdTOp3wIB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_until_best(model, save_path, train_batched=None, val_batched=None, verbose=1):\n",
        "    # Compile model\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=1e-3\n",
        "    )\n",
        "\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=2,\n",
        "    )\n",
        "\n",
        "    get_best_weights = GetBestWeights(\"val_loss\")\n",
        "\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        optimizer=optimizer,\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
        "    )\n",
        "\n",
        "    # Default data\n",
        "    if not train_batched:\n",
        "        train_batched = train.batch(16)\n",
        "\n",
        "    if not val_batched:\n",
        "        val_batched = val.batch(16)\n",
        "\n",
        "    # Train on high learning rate\n",
        "    model.fit(\n",
        "        x=train_batched,\n",
        "        validation_data=val_batched,\n",
        "        callbacks=[early_stopping, get_best_weights],\n",
        "        epochs=10,\n",
        "        verbose=verbose\n",
        "    )\n",
        "\n",
        "    # Recover to best weights\n",
        "    best_weights = get_best_weights.best_weights\n",
        "    model.set_weights(best_weights)\n",
        "\n",
        "    # Train on lower learning rate\n",
        "    optimizer.learning_rate = 1e-4\n",
        "\n",
        "    model.fit(\n",
        "        x=train_batched,\n",
        "        validation_data=val_batched,\n",
        "        callbacks=[early_stopping, get_best_weights],\n",
        "        epochs=10,\n",
        "        verbose=verbose\n",
        "    )\n",
        "\n",
        "    # Save best weights\n",
        "    best_weights = get_best_weights.best_weights\n",
        "    model.set_weights(best_weights)\n",
        "    model.save_weights(save_path)"
      ],
      "metadata": {
        "id": "YsYchNDWHseN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Relatively) Large Baseline Model"
      ],
      "metadata": {
        "id": "cT06J4_NzTEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "large_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(\n",
        "        shape=(382, 512, 3)\n",
        "    ),\n",
        "    tf.keras.layers.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(8, 8),\n",
        "    ),\n",
        "    tf.keras.layers.AveragePooling2D(\n",
        "        pool_size=(2, 2)\n",
        "    ),\n",
        "    tf.keras.layers.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(8, 8),\n",
        "    ),\n",
        "    tf.keras.layers.AveragePooling2D(\n",
        "        pool_size=(4, 4)\n",
        "    ),\n",
        "    tf.keras.layers.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(8, 8),\n",
        "    ),\n",
        "    tf.keras.layers.MaxPool2D(\n",
        "        pool_size=(4, 4)\n",
        "    ),\n",
        "    tf.keras.layers.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(4, 4),\n",
        "    ),\n",
        "    tf.keras.layers.MaxPool2D(\n",
        "        pool_size=(4, 4)\n",
        "    ),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(32),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(1),\n",
        "    tf.keras.layers.Activation(\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "oPq6Vzv167ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train and Save Weights"
      ],
      "metadata": {
        "id": "ek7DwzWu5Pk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load Saved Weights"
      ],
      "metadata": {
        "id": "zz0xbmte5Zbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "large_model.load_weights(f\"{DATA_PATH}/large.weights.h5\")"
      ],
      "metadata": {
        "id": "Dk4UEE6b16NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Smaller Models"
      ],
      "metadata": {
        "id": "VJ2EggmV61iH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def layer_skipped_model(layer_mask):\n",
        "    # layer_mask must be a boolean list of length 4\n",
        "    assert len(layer_mask) == 4\n",
        "    assert sum([type(i) == bool for i in layer_mask]) == 4\n",
        "\n",
        "    # Define layers\n",
        "    layer_1 = [\n",
        "        tf.keras.layers.Conv2D(\n",
        "            filters=4,\n",
        "            kernel_size=(8, 8),\n",
        "        ),\n",
        "        tf.keras.layers.AveragePooling2D(\n",
        "            pool_size=(2, 2)\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    layer_2 = [\n",
        "        tf.keras.layers.Conv2D(\n",
        "            filters=8,\n",
        "            kernel_size=(8, 8),\n",
        "        ),\n",
        "        tf.keras.layers.AveragePooling2D(\n",
        "            pool_size=(4, 4)\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    layer_3 = [\n",
        "        tf.keras.layers.Conv2D(\n",
        "            filters=16,\n",
        "            kernel_size=(8, 8),\n",
        "        ),\n",
        "        tf.keras.layers.MaxPool2D(\n",
        "            pool_size=(4, 4)\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    layer_4 = [\n",
        "        tf.keras.layers.Conv2D(\n",
        "            filters=32,\n",
        "            kernel_size=(4, 4),\n",
        "        ),\n",
        "        tf.keras.layers.MaxPool2D(\n",
        "            pool_size=(4, 4)\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    layers = [layer_1, layer_2, layer_3, layer_4]\n",
        "\n",
        "    # Begin sequence\n",
        "    sequence = [\n",
        "        tf.keras.layers.InputLayer(\n",
        "            shape=(382, 512, 3)\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Add layers with skipping\n",
        "    skipped_pool_multiplier = 1\n",
        "    for i, skipped in enumerate(layer_mask):\n",
        "        # Get layer information\n",
        "        layer = layers[i]\n",
        "        pool_size = layer[1].pool_size[0]\n",
        "\n",
        "        # Skip layer and record amount of pool balancing needed\n",
        "        if skipped:\n",
        "            skipped_pool_multiplier *= pool_size\n",
        "            continue\n",
        "\n",
        "        # Compute new pool size\n",
        "        new_pool_size = pool_size * skipped_pool_multiplier\n",
        "\n",
        "        # Reset skipped pool multiplier (new pool size compensates for skipped)\n",
        "        skipped_pool_multiplier = 1\n",
        "\n",
        "        # Update layer pool size\n",
        "        layer[1].pool_size = (new_pool_size, new_pool_size)\n",
        "        layer[1].strides = layer[1].pool_size # consistent with default tf\n",
        "\n",
        "        # Add conv and pool layers to sequence\n",
        "        sequence += layer\n",
        "\n",
        "    # Add extra pooling if needed\n",
        "    if skipped_pool_multiplier != 1:\n",
        "        extra_pool = tf.keras.layers.MaxPool2D(\n",
        "            pool_size=(skipped_pool_multiplier, skipped_pool_multiplier)\n",
        "        )\n",
        "\n",
        "        sequence.append(extra_pool)\n",
        "\n",
        "    # Complete sequence\n",
        "    sequence += [\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(32),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(1),\n",
        "        tf.keras.layers.Activation(\"sigmoid\")\n",
        "    ]\n",
        "\n",
        "    # Create model from sequence\n",
        "    return tf.keras.Sequential(sequence)"
      ],
      "metadata": {
        "id": "PJScQM0265Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling tests\n",
        "- Plot val accuracy vs param count\n",
        "- Examine target task proficiency vs param count"
      ],
      "metadata": {
        "id": "V-QR8t9vGGmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_counts = []\n",
        "val_accs = []"
      ],
      "metadata": {
        "id": "AGVi3HBYG3cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline"
      ],
      "metadata": {
        "id": "UhY53ExGH3pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_counts.append(count_params(large_model))\n",
        "val_accs.append(get_acc(large_model, val.batch(16)))"
      ],
      "metadata": {
        "id": "TmvrDzuSH6fF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Smaller"
      ],
      "metadata": {
        "id": "t9f5afjfIyhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 16):\n",
        "    skip_mask = [c == \"1\" for c in bin(i)[2:].zfill(4)]\n",
        "\n",
        "    acc_sum = 0\n",
        "\n",
        "    print(f\"Training model {i}/15:\")\n",
        "\n",
        "    for j, seed in enumerate(SEEDS):\n",
        "        tf.random.set_seed(seed)\n",
        "\n",
        "        model = layer_skipped_model(skip_mask)\n",
        "\n",
        "        print(f\"Training Seed {j+1}/{len(SEEDS)} ... \", end=\"\")\n",
        "        train_until_best(model, f\"scaled{i}_{j}.weights.h5\", verbose=0)\n",
        "        print(\"Done!\")\n",
        "\n",
        "        acc_sum += get_acc(model, val.batch(16))\n",
        "\n",
        "    param_counts.append(count_params(model))\n",
        "    val_accs.append(acc_sum/len(SEEDS))\n",
        "\n",
        "    print(f\"Stats - {param_counts[-1]} params, {val_accs[-1]:.5f} val acc\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MAqJtn7lJRPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_file_names = []\n",
        "\n",
        "for i in range(1, 16):\n",
        "    for j in range(4):\n",
        "        all_file_names.append(f\"scaled{i}_{j}.weights.h5\")"
      ],
      "metadata": {
        "id": "7sLCMZS9EugO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir(\"scaled models\")\n",
        "\n",
        "for file_name in all_file_names:\n",
        "    os.rename(file_name, f\"scaled models/{file_name}\")"
      ],
      "metadata": {
        "id": "n6TdwIyzFRD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive(\"scaled models\", \"zip\", \"scaled models\")"
      ],
      "metadata": {
        "id": "2ZbK5MxoF_ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis"
      ],
      "metadata": {
        "id": "kPeNx7hvis8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip small models\n",
        "with zipfile.ZipFile(f\"{DATA_PATH}/scaled models.zip\", 'r') as f:\n",
        "    f.extractall(\"/content\")"
      ],
      "metadata": {
        "id": "QEazKFzakQ03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(weights_file_name):\n",
        "    i = int(weights_file_name[6:].split(\"_\")[0])\n",
        "    skip_mask = [c == \"1\" for c in bin(i)[2:].zfill(4)]\n",
        "\n",
        "    model = layer_skipped_model(skip_mask)\n",
        "\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
        "    )\n",
        "\n",
        "    model.load_weights(weights_file_name)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "mpQs_gMziyfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {}\n",
        "\n",
        "for i in range(1, 16):\n",
        "    temp = []\n",
        "\n",
        "    for j in range(4):\n",
        "        temp.append(build_model(f\"scaled{i}_{j}.weights.h5\"))\n",
        "\n",
        "    params = count_params(temp[-1])\n",
        "    models[params] = temp"
      ],
      "metadata": {
        "id": "V3n82NgvkGBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_counts = sorted(list(models.keys()))"
      ],
      "metadata": {
        "id": "HFqc0dQllXxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sample(n, ds):\n",
        "    i = 0\n",
        "\n",
        "    for img, y in ds:\n",
        "        if i != n:\n",
        "            i += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "4Cs-4PpIaOtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saliency Maps"
      ],
      "metadata": {
        "id": "JU9vFQoYzGzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fence_crash = get_sample(5, fence)\n",
        "\n",
        "plt.imshow(fence_crash)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cgws42HsmFZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fence_drive = get_sample(10, fence)\n",
        "\n",
        "plt.imshow(fence_drive)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R5qi3B5ksa_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def group_saliency(params, x):\n",
        "    maps = [get_saliency(model, x) for model in models[params]]\n",
        "\n",
        "    summed = np.sum(np.concatenate(maps, axis=0), axis=0)\n",
        "\n",
        "    return np.min([summed, np.ones_like(summed)], axis=0)"
      ],
      "metadata": {
        "id": "yQkxDU-0naMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_count in param_counts:\n",
        "    plt.axis('off')\n",
        "    plt.imshow(fence_drive)\n",
        "    plt.imshow(group_saliency(param_count, fence_drive), cmap=\"jet\", alpha=0.3)\n",
        "    plt.title(f\"{param_count} params\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aMxtwCrNFuF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_count in param_counts:\n",
        "    plt.axis('off')\n",
        "    plt.imshow(fence_crash)\n",
        "    plt.imshow(group_saliency(param_count, fence_crash), cmap=\"jet\", alpha=0.3)\n",
        "    plt.title(f\"{param_count} params\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9R263cgjtTBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guard_crash = get_sample(20, guard)\n",
        "\n",
        "plt.imshow(guard_crash)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0dpo2lUyanxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guard_drive = get_sample(5, guard)\n",
        "\n",
        "plt.imshow(guard_drive)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G7B3laWhaz0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_count in param_counts:\n",
        "    plt.axis('off')\n",
        "    plt.imshow(guard_drive)\n",
        "    plt.imshow(group_saliency(param_count, guard_drive), cmap=\"jet\", alpha=0.3)\n",
        "    plt.title(f\"{param_count} params\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-k89DM4Ka7Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_count in param_counts:\n",
        "    plt.axis('off')\n",
        "    plt.imshow(guard_crash)\n",
        "    plt.imshow(group_saliency(param_count, guard_crash), cmap=\"jet\", alpha=0.3)\n",
        "    plt.title(f\"{param_count} params\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "NAg0mBuWa9Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hard_crash = get_sample(5, hard)\n",
        "\n",
        "plt.imshow(hard_crash)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pcnLvR1ZiYAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hard_drive = get_sample(20, hard)\n",
        "\n",
        "plt.imshow(hard_drive)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RiT9bhlsjLm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_count in param_counts:\n",
        "    plt.axis('off')\n",
        "    plt.imshow(hard_crash)\n",
        "    plt.imshow(group_saliency(param_count, hard_crash), cmap=\"jet\", alpha=0.3)\n",
        "    plt.title(f\"{param_count} params\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Va6al_PFivO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_count in param_counts:\n",
        "    plt.axis('off')\n",
        "    plt.imshow(hard_drive)\n",
        "    plt.imshow(group_saliency(param_count, hard_drive), cmap=\"jet\", alpha=0.3)\n",
        "    plt.title(f\"{param_count} params\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "nqL3PKVNjtbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaling Curves"
      ],
      "metadata": {
        "id": "Tk3eGR5dzLD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaling_curve(test_set):\n",
        "    y_min = []\n",
        "    y = []\n",
        "    y_max = []\n",
        "\n",
        "    for param_count in tqdm(param_counts):\n",
        "        accs = []\n",
        "\n",
        "        for model in models[param_count]:\n",
        "            loss, acc = model.evaluate(\n",
        "                x=test_set.batch(16),\n",
        "                verbose=0\n",
        "            )\n",
        "\n",
        "            accs.append(acc)\n",
        "\n",
        "        accs = np.array(accs)\n",
        "\n",
        "        y_min.append(accs.min())\n",
        "        y.append(accs.mean())\n",
        "        y_max.append(accs.max())\n",
        "\n",
        "    return {\"min\": y_min, \"mean\": y, \"max\": y_max}"
      ],
      "metadata": {
        "id": "KzBpbdkFCKy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_curve = scaling_curve(val)"
      ],
      "metadata": {
        "id": "ZhxecneKF-kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fence_curve = scaling_curve(fence)"
      ],
      "metadata": {
        "id": "FBPMPfnlubv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fence\n",
        "plt.plot(param_counts, fence_curve[\"mean\"], label=\"Wood Fence\")\n",
        "plt.fill_between(param_counts, fence_curve[\"min\"], fence_curve[\"max\"], alpha=0.3)\n",
        "\n",
        "plt.plot(param_counts, val_curve[\"mean\"], linestyle=\"--\", alpha=0.5, label=\"Validation\")\n",
        "plt.fill_between(param_counts, val_curve[\"min\"], val_curve[\"max\"], alpha=0.2)\n",
        "\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.xlabel(\"Parameters\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u-8h_pFxMEMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "easy_curve = scaling_curve(easy)"
      ],
      "metadata": {
        "id": "GuI-s9LnudiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Easy\n",
        "plt.plot(param_counts, easy_curve[\"mean\"], label=\"Easy\")\n",
        "plt.fill_between(param_counts, easy_curve[\"min\"], easy_curve[\"max\"], alpha=0.3)\n",
        "\n",
        "plt.plot(param_counts, val_curve[\"mean\"], linestyle=\"--\", alpha=0.5, label=\"Validation\")\n",
        "plt.fill_between(param_counts, val_curve[\"min\"], val_curve[\"max\"], alpha=0.2)\n",
        "\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.xlabel(\"Parameters\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w3iJL4F-Qtor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hard_curve = scaling_curve(hard)"
      ],
      "metadata": {
        "id": "2J1XSMs2ufQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hard\n",
        "plt.plot(param_counts, hard_curve[\"mean\"], label=\"Hard\")\n",
        "plt.fill_between(param_counts, hard_curve[\"min\"], hard_curve[\"max\"], alpha=0.3)\n",
        "\n",
        "plt.plot(param_counts, val_curve[\"mean\"], linestyle=\"--\", alpha=0.5, label=\"Validation\")\n",
        "plt.fill_between(param_counts, val_curve[\"min\"], val_curve[\"max\"], alpha=0.2)\n",
        "\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.xlabel(\"Parameters\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DoOVKPZ7Q939"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guard_curve = scaling_curve(guard)"
      ],
      "metadata": {
        "id": "kdpL2yOyugcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guard\n",
        "plt.plot(param_counts, guard_curve[\"mean\"], label=\"Metal Guard\")\n",
        "plt.fill_between(param_counts, guard_curve[\"min\"], guard_curve[\"max\"], alpha=0.3)\n",
        "\n",
        "plt.plot(param_counts, val_curve[\"mean\"], linestyle=\"--\", alpha=0.5, label=\"Validation\")\n",
        "plt.fill_between(param_counts, val_curve[\"min\"], val_curve[\"max\"], alpha=0.2)\n",
        "\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.xlabel(\"Parameters\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9sxxtMCBRRxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Val\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "\n",
        "plt.plot(param_counts, val_curve[\"mean\"], c=\"C1\")\n",
        "plt.fill_between(param_counts, val_curve[\"min\"], val_curve[\"max\"], alpha=0.3, color=\"C1\")\n",
        "plt.xlabel(\"Parameters\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3s3Cfv0QuDM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guard v Fence Comparison\n",
        "plt.plot(param_counts, guard_curve[\"mean\"], label=\"Metal Guard\", c=\"C2\")\n",
        "plt.fill_between(param_counts, guard_curve[\"min\"], guard_curve[\"max\"], alpha=0.3, color=\"C2\")\n",
        "\n",
        "plt.plot(param_counts, fence_curve[\"mean\"], label=\"Wood Fence\", c=\"C5\")\n",
        "plt.fill_between(param_counts, fence_curve[\"min\"], fence_curve[\"max\"], alpha=0.3, color=\"C5\")\n",
        "\n",
        "plt.plot(param_counts, val_curve[\"mean\"], linestyle=\"--\", alpha=0.5, label=\"Validation\", c=\"C1\")\n",
        "plt.fill_between(param_counts, val_curve[\"min\"], val_curve[\"max\"], alpha=0.2, color=\"C1\")\n",
        "\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.xlabel(\"Parameters\")\n",
        "# plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v45xpLpzex1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Easy v Hard Comparison\n",
        "plt.plot(param_counts, easy_curve[\"mean\"], label=\"Easy\", c=\"C3\")\n",
        "plt.fill_between(param_counts, easy_curve[\"min\"], easy_curve[\"max\"], alpha=0.3, color=\"C3\")\n",
        "\n",
        "plt.plot(param_counts, hard_curve[\"mean\"], label=\"Hard\", c=\"C4\")\n",
        "plt.fill_between(param_counts, hard_curve[\"min\"], hard_curve[\"max\"], alpha=0.3, color=\"C4\")\n",
        "\n",
        "plt.plot(param_counts, val_curve[\"mean\"], linestyle=\"--\", alpha=0.5, label=\"Validation\", c=\"C1\")\n",
        "plt.fill_between(param_counts, val_curve[\"min\"], val_curve[\"max\"], alpha=0.2, color=\"C1\")\n",
        "\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.xlabel(\"Parameters\")\n",
        "# plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WncX05ELhV7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extras\n",
        "\n",
        "Below are shortcuts to set the raw results I obtained"
      ],
      "metadata": {
        "id": "MwljF1tQ97uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_counts = sorted([14173, 13165, 4429, 19317, 8021, 9061, 1605, 20089, 12889, 11881, 3145, 17521, 6225, 7777, 833])"
      ],
      "metadata": {
        "id": "6a7h_QI6-WHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_curve = {'min': [0.5249999761581421,\n",
        "  0.4399999976158142,\n",
        "  0.5699999928474426,\n",
        "  0.7749999761581421,\n",
        "  0.625,\n",
        "  0.44999998807907104,\n",
        "  0.7724999785423279,\n",
        "  0.7124999761581421,\n",
        "  0.8575000166893005,\n",
        "  0.8475000262260437,\n",
        "  0.8450000286102295,\n",
        "  0.8424999713897705,\n",
        "  0.9300000071525574,\n",
        "  0.9225000143051147,\n",
        "  0.8224999904632568],\n",
        " 'mean': [0.5456249862909317,\n",
        "  0.6050000041723251,\n",
        "  0.6068750023841858,\n",
        "  0.809374988079071,\n",
        "  0.6724999994039536,\n",
        "  0.5487499982118607,\n",
        "  0.7981249988079071,\n",
        "  0.7406249940395355,\n",
        "  0.8668750077486038,\n",
        "  0.8656250089406967,\n",
        "  0.8681250065565109,\n",
        "  0.8693749904632568,\n",
        "  0.9474999904632568,\n",
        "  0.9506250023841858,\n",
        "  0.8599999994039536],\n",
        " 'max': [0.5799999833106995,\n",
        "  0.6800000071525574,\n",
        "  0.6575000286102295,\n",
        "  0.8274999856948853,\n",
        "  0.6949999928474426,\n",
        "  0.6299999952316284,\n",
        "  0.8349999785423279,\n",
        "  0.7549999952316284,\n",
        "  0.8824999928474426,\n",
        "  0.875,\n",
        "  0.8774999976158142,\n",
        "  0.8924999833106995,\n",
        "  0.9574999809265137,\n",
        "  0.9700000286102295,\n",
        "  0.8849999904632568]}"
      ],
      "metadata": {
        "id": "kvQo29Og987O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fence_curve = {'min': [0.6666666865348816,\n",
        "  0.21875,\n",
        "  0.4166666567325592,\n",
        "  0.5208333134651184,\n",
        "  0.25,\n",
        "  0.2395833283662796,\n",
        "  0.6354166865348816,\n",
        "  0.46875,\n",
        "  0.625,\n",
        "  0.6354166865348816,\n",
        "  0.6666666865348816,\n",
        "  0.6770833134651184,\n",
        "  0.9895833134651184,\n",
        "  0.7083333134651184,\n",
        "  0.65625],\n",
        " 'mean': [0.6927083283662796,\n",
        "  0.4531249925494194,\n",
        "  0.4921875,\n",
        "  0.5442708283662796,\n",
        "  0.3307291716337204,\n",
        "  0.3619791604578495,\n",
        "  0.7265625149011612,\n",
        "  0.5833333283662796,\n",
        "  0.6640625149011612,\n",
        "  0.6510416567325592,\n",
        "  0.7187500149011612,\n",
        "  0.703125,\n",
        "  0.9973958283662796,\n",
        "  0.9192708283662796,\n",
        "  0.6874999850988388],\n",
        " 'max': [0.71875,\n",
        "  0.8020833134651184,\n",
        "  0.5625,\n",
        "  0.5729166865348816,\n",
        "  0.5104166865348816,\n",
        "  0.5625,\n",
        "  0.7916666865348816,\n",
        "  0.7708333134651184,\n",
        "  0.6979166865348816,\n",
        "  0.6770833134651184,\n",
        "  0.78125,\n",
        "  0.7604166865348816,\n",
        "  1.0,\n",
        "  1.0,\n",
        "  0.7083333134651184]}"
      ],
      "metadata": {
        "id": "qEEWFVCk9_hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hard_curve = {'min': [0.6145833134651184,\n",
        "  0.1979166716337204,\n",
        "  0.3333333432674408,\n",
        "  0.2708333432674408,\n",
        "  0.3333333432674408,\n",
        "  0.3020833432674408,\n",
        "  0.4583333432674408,\n",
        "  0.46875,\n",
        "  0.75,\n",
        "  0.7083333134651184,\n",
        "  0.7708333134651184,\n",
        "  0.6145833134651184,\n",
        "  0.9270833134651184,\n",
        "  0.9583333134651184,\n",
        "  0.8229166865348816],\n",
        " 'mean': [0.6822916716337204,\n",
        "  0.3489583320915699,\n",
        "  0.6223958432674408,\n",
        "  0.6744791641831398,\n",
        "  0.5078124925494194,\n",
        "  0.4062499925494194,\n",
        "  0.643229179084301,\n",
        "  0.5338541716337204,\n",
        "  0.7994791716337204,\n",
        "  0.7473958432674408,\n",
        "  0.8020833283662796,\n",
        "  0.7161458283662796,\n",
        "  0.9609375,\n",
        "  0.9713541716337204,\n",
        "  0.8307291716337204],\n",
        " 'max': [0.7604166865348816,\n",
        "  0.5,\n",
        "  0.8541666865348816,\n",
        "  0.875,\n",
        "  0.6145833134651184,\n",
        "  0.5208333134651184,\n",
        "  0.7604166865348816,\n",
        "  0.59375,\n",
        "  0.8541666865348816,\n",
        "  0.8229166865348816,\n",
        "  0.8333333134651184,\n",
        "  0.7916666865348816,\n",
        "  0.9791666865348816,\n",
        "  0.9791666865348816,\n",
        "  0.84375]}"
      ],
      "metadata": {
        "id": "oo2AAOgd-C2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "easy_curve = {'min': [0.7916666865348816,\n",
        "  0.4583333432674408,\n",
        "  0.4375,\n",
        "  0.90625,\n",
        "  0.7291666865348816,\n",
        "  0.5,\n",
        "  0.96875,\n",
        "  0.9375,\n",
        "  0.9166666865348816,\n",
        "  0.8958333134651184,\n",
        "  0.90625,\n",
        "  0.8958333134651184,\n",
        "  0.96875,\n",
        "  0.9375,\n",
        "  0.8958333134651184],\n",
        " 'mean': [0.8098958432674408,\n",
        "  0.6953125074505806,\n",
        "  0.5364583358168602,\n",
        "  0.9479166567325592,\n",
        "  0.8177083283662796,\n",
        "  0.65625,\n",
        "  0.984375,\n",
        "  0.9661458432674408,\n",
        "  0.9322916716337204,\n",
        "  0.9192708283662796,\n",
        "  0.9296875,\n",
        "  0.9244791567325592,\n",
        "  0.9791666567325592,\n",
        "  0.9557291716337204,\n",
        "  0.9010416567325592],\n",
        " 'max': [0.84375,\n",
        "  0.90625,\n",
        "  0.78125,\n",
        "  0.9895833134651184,\n",
        "  0.96875,\n",
        "  0.8229166865348816,\n",
        "  1.0,\n",
        "  1.0,\n",
        "  0.9479166865348816,\n",
        "  0.9375,\n",
        "  0.9583333134651184,\n",
        "  0.9583333134651184,\n",
        "  0.9895833134651184,\n",
        "  0.9791666865348816,\n",
        "  0.90625]}"
      ],
      "metadata": {
        "id": "CKMprKUu-EGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guard_curve = {'min': [0.6354166865348816,\n",
        "  0.4895833432674408,\n",
        "  0.4791666567325592,\n",
        "  0.8333333134651184,\n",
        "  0.7708333134651184,\n",
        "  0.4895833432674408,\n",
        "  0.9791666865348816,\n",
        "  0.8645833134651184,\n",
        "  0.9166666865348816,\n",
        "  0.9375,\n",
        "  0.9270833134651184,\n",
        "  0.9583333134651184,\n",
        "  0.96875,\n",
        "  0.96875,\n",
        "  0.9270833134651184],\n",
        " 'mean': [0.6927083283662796,\n",
        "  0.690104179084301,\n",
        "  0.5703124925494194,\n",
        "  0.8828124850988388,\n",
        "  0.8229166567325592,\n",
        "  0.6562500074505806,\n",
        "  0.9947916716337204,\n",
        "  0.9609375,\n",
        "  0.9427083432674408,\n",
        "  0.9609375,\n",
        "  0.9401041716337204,\n",
        "  0.9817708283662796,\n",
        "  0.9765625,\n",
        "  0.9843749850988388,\n",
        "  0.9374999850988388],\n",
        " 'max': [0.75,\n",
        "  0.9166666865348816,\n",
        "  0.8333333134651184,\n",
        "  0.9270833134651184,\n",
        "  0.8958333134651184,\n",
        "  0.8125,\n",
        "  1.0,\n",
        "  1.0,\n",
        "  0.9791666865348816,\n",
        "  0.9895833134651184,\n",
        "  0.9479166865348816,\n",
        "  1.0,\n",
        "  0.9895833134651184,\n",
        "  0.9895833134651184,\n",
        "  0.96875]}"
      ],
      "metadata": {
        "id": "DLpn86os-HTd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}